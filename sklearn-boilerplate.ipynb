{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheat sheet: https://www.datacamp.com/community/blog/scikit-learn-cheat-sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# TODO review most popular/useful models: RF, decision tree, logistic regr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO what are all the possible steps?\n",
    "\n",
    "# TODO add feature selection steps\n",
    "# TODO add sequential selection\n",
    "\n",
    "# TODO plot feature importances with random forests\n",
    "\n",
    "# TODO example with OHE -> pandas get_dummies?\n",
    "# TODO what is feature extraction?\n",
    "\n",
    "\n",
    "# Only used in binary classification\n",
    "from sklearn.metrics import plot_roc_curve \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TODO add a binary classification example\n",
    "\n",
    "# TODO find most useful fns in sklearn\n",
    "\n",
    "# TODO what to do with mixed feature types\n",
    "\n",
    "# TODO add clustering algorithm examples, meanshift, etc.\n",
    "    # TODO use iris for this\n",
    "# TODO check some time series algorithms\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "# MAYBE check out the column transformer (for preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "data_mnist = load_digits(as_frame=True)\n",
    "\n",
    "X = data_mnist['data']\n",
    "y = data_mnist['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    random_state=42,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__reg_alpha': 0.0001, 'pca__n_components': 30}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline_steps = [\n",
    "    ('pca', PCA()),\n",
    "#     ('clf', LogisticRegression())\n",
    "    ('clf', XGBClassifier())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(pipeline_steps)\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [5, 15, 30, 45, 64], # Take first N components with highest variance\n",
    "#     'clf__C': np.logspace(-4, 4, 4),\n",
    "    'clf__reg_alpha': np.logspace(-4, 4, 4),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.963395421713836\n",
      "Accuracy score: 0.9638888888888889\n",
      "Precision score: 0.9644667442528794\n",
      "Recall score: 0.9631173571943286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        33\n",
      "           1       0.96      0.96      0.96        28\n",
      "           2       0.92      1.00      0.96        33\n",
      "           3       0.97      0.97      0.97        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.92      0.96      0.94        47\n",
      "           6       1.00      0.97      0.99        35\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.93      0.93      0.93        30\n",
      "           9       0.97      0.93      0.95        40\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average='macro')) # Mean F1 value for the multi-label case\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred)) # Mean F1 value for the multi-label case\n",
    "print(\"Precision score:\", precision_score(y_test, y_pred, average='macro')) # Mean F1 value for the multi-label case\n",
    "print(\"Recall score:\", recall_score(y_test, y_pred, average='macro')) # Mean F1 value for the multi-label case\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "multilabel_confusion_matrix(y_test, y_pred) # TODO display these matrices\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "Regression example, Boston housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data_boston = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data_boston['data'], columns=data_boston.feature_names)\n",
    "y = data_boston['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    random_state=42,\n",
    "    test_size=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import Normalizer # TODO check what this does exactly\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RandomForestRegressor\n",
    "\n",
    "steps = [\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('randomForestRegressor', RandomForestRegressor())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimisation\n",
    "parameters = {\n",
    "#     'logisticRegression__C':[0.001,0.1,1.0,10.0],\n",
    "#     'logisticRegression__penalty':['l1', 'l2', 'elasticnet', 'none']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=parameters,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 1.0\n",
      "{'logisticRegression__C': 0.1, 'logisticRegression__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# TODO plot residuals in regression\n",
    "residuals = y_test - y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
